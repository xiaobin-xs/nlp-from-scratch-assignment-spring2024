Technological Univ ersity Dublin Technological Univ ersity Dublin 
ARROW@TU Dublin ARROW@TU Dublin 
Conf erence papers School of Computer Science 
2023 
Queer In AI: A Case Study in Community-Led P articipat ory AI Queer In AI: A Case Study in Community-Led P articipat ory AI 
Anaelia Ov alle 
Univ ersity of California, USA 
Arjun Subr amonian 
Univ ersity of California, USA 
Ashwiin Singh 
Queer in AI, India 
See next page for additional authors 
Follow this and additional works at: https:/ /arrow.tudublin.ie/scschcomcon 
 Part of the Computer Engineering Commons , and the Social and Beha vioral Sciences Commons 
Recommended Citation Recommended Citation 
Ovalle, Anaelia; Subr amonian, Arjun; Singh, Ashwiin; V oelck er, Claas; Sutherland, Danica; Locatelli, Da vide; 
Breznik, E va; Klubicka, F elip; Y uan, Hang; J, Hetvi; Zhang, Huan; Shrir am, Jaide v; Lehman, Kruno; Soldaini, 
Luca; Sap, Maar ten; Deisenr oth, Mar c Peter; P acheco, Maria Leonor; Ryskina, Maria; Mundt, Mar tin; 
Agar wal, Melind; McLean, Nyx; X u, Pan; Pr anav, A.; K orpan, Raj; Ra y, Ruchir a; Mathew , Sar ah; Ar ora, 
Sarthak; John, S.T .; Anand, T anvi; Agr awal, Vishakha; Agnew , William; Long, Y anan; W ang, Zijie J.; T alat, 
Zeerak; Ghosh, A vijit; Dennler , Nathaniel; Nosewor thy, Michael; Jha, Shar vani; Ba ylor, Emi; Joshi, Adity a; 
Bilenko, Natalia Y .; McNamar a, Andr ew; Gontijo-Lopes, Raphael; Markham, Alex; Dong, E vyn; Ka y, Jackie; 
Saraswat, Manu; V ytla, Nikhil; and Stark, L uke, "Queer In AI: A Case Study in Community-Led P articipat ory 
AI" (2023). Conf erence papers . 407. 
https:/ /arrow.tudublin.ie/scschcomcon/407 
This Conf erence P aper is br ought t o you for fr ee and open access b y the School of Computer Science at 
ARROW@TU Dublin. It has been accepted for inclusion in Conf erence papers b y an authoriz ed administr ator of 
ARROW@TU Dublin. F or mor e information, please contact arrow.admin@tudublin.ie, aisling.co yne@tudublin.ie, 
gerard.connolly@tudublin.ie, v era.kilshaw@tudublin.ie . 
This work is licensed under a Creativ e Commons A ttribution-Shar e Alik e 4.0 International License . 
Authors Authors 
Anaelia Ov alle, Arjun Subr amonian, Ashwiin Singh, Claas V oelck er, Danica Sutherland, Da vide Locatelli, 
Eva Breznik, F elip Klubicka, Hang Y uan, Hetvi J, Huan Zhang, Jaide v Shrir am, Kruno Lehman, L uca 
Soldaini, Maar ten Sap, Mar c Peter Deisenr oth, Maria Leonor P acheco, Maria Ryskina, Mar tin Mundt, 
Melind Agar wal, Nyx McLean, P an X u, A. Pr anav, Raj K orpan, Ruchir a Ra y, Sar ah Mathew , Sar thak Ar ora, 
S.T. John, T anvi Anand, Vishakha Agr awal, William Agnew , Yanan Long, Zijie J. W ang, Z eerak Talat, A vijit 
Ghosh, Nathaniel Dennler , Michael Nosewor thy, Shar vani Jha, Emi Ba ylor, Adity a Joshi, Natalia Y . Bilenko, 
Andr ew McNamar a, Raphael Gontijo-Lopes, Alex Markham, E vyn Dong, Jackie Ka y, Manu Sar aswat, Nikhil 
Vytla, and L uke Stark 
This conf erence paper is a vailable at ARROW@TU Dublin: https:/ /arrow.tudublin.ie/scschcomcon/407 
Queer In AI: A Case Study in Community-Led Participatory AI
Organizers of QueerInAI
Queer in AI
Many CountriesAnaelia Ovalle
Queer in AI & University of
California, Los Angeles
USAArjun Subramonian
Queer in AI & University of
California, Los Angeles
USA
Ashwin Singh
Queer in AI
IndiaClaas Voelcker
Queer in AI & University of Toronto,
Vector Institute
CanadaDanica J. Sutherland
Queer in AI & University of British
Columbia & Amii
Canada
Davide Locatelli
Queer in AI
SpainEva Breznik
Queer in AI & Uppsala University
SwedenFilip Klubička
Queer in AI & ADAPT Centre,
Technological University Dublin
Ireland
Hang Yuan
Queer in AI
United KingdomHetvi J
Queer in AI
United KingdomHuan Zhang
Queer in AI
USA
Jaidev Shriram
Queer in AI & University of
California, San Diego
USAKruno Lehman
Queer in AI
SwitzerlandLuca Soldaini
Queer in AI & Allen Institute for AI
USA
Maarten Sap
Queer in AI & Language Technologies
Institute, Carnegie Mellon University
& Allen Institute for AI
USAMarc Peter Deisenroth
Queer in AI & University College
London
United KingdomMaria Leonor Pacheco
Queer in AI & University of Colorado
Boulder
USA
Maria Ryskina
Queer in AI & MIT
USAMartin Mundt
Queer in AI & TU Darmstadt &
hessian.AI
GermanyMilind Agarwal
Queer in AI & George Mason
University
USA
Nyx McLean
Queer in AI & Rhodes University
South AfricaPan Xu
Queer in AI & Duke University
USAA Pranav
Queer in AI
Hong Kong
Raj Korpan
Queer in AI & Iona University
USARuchira Ray
Queer in AI
USASarah Mathew
Queer in AI & Georgia Institute of
Technology
USA
Sarthak Arora
Queer in AI
IndiaST John
Queer in AI & Aalto University
FinlandTanvi Anand
Queer in AI
USA
1882

Vishakha Agrawal
Queer in AI
IndiaWilliam Agnew
Queer in AI & University of
Washington
USAYanan Long
Queer in AI & University of Chicago
USA
Zijie J. Wang
Queer in AI & Georgia Tech
USAZeerak Talat
Queer in AI
CanadaAvijit Ghosh
Queer in AI & Northeastern
University
USA
Nathaniel Dennler
Queer In AI
USAMichael Noseworthy
Queer In AI & MIT
USASharvani Jha
Queer In AI
USA
Emi Baylor
Queer In AI
CanadaAditya Joshi
Queer In AI & SEEK, Australia
AustraliaNatalia Y. Bilenko
Queer in AI
USA
Andrew McNamara
Queer in AI & Microsoft
CanadaRaphael Gontijo-Lopes
Queer in AI
USAAlex Markham
Queer in AI
Sweden
Evyn D ˇong
Queer in AI
USAJackie Kay
Queer in AI
United KingdomManu Saraswat
Queer in AI
Canada
Nikhil Vytla
Queer in AI
USALuke Stark
Queer in AI & Western University
Canada
ABSTRACT
Queerness and queer people face an uncertain future in the face
of ever more widely deployed and invasive artificial intelligence
(AI). These technologies have caused numerous harms to queer
people, including privacy violations, censoring and downranking
queer content, exposing queer people and spaces to harassment
by making them hypervisible, deadnaming and outing queer peo-
ple. More broadly, they have violated core tenets of queerness by
classifying and controlling queer identities. In response to this, the
queer community in AI has organized Queer in AI, a global, de-
centralized, volunteer-run grassroots organization that employs
intersectional and community-led participatory design to build an
inclusive and equitable AI future. In this paper, we present Queer in
AI as a case study for community-led participatory design in AI. We
examine how participatory design and intersectional tenets started
and shaped this community’s programs over the years. We discuss
different challenges that emerged in the process, look at ways this
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
FAccT ’23, June 12–15, 2023, Chicago, IL, USA
©2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0192-4/23/06. . . $15.00
https://doi.org/10.1145/3593013.3594134organization has fallen short of operationalizing participatory and
intersectional principles, and then assess the organization’s impact.
Queer in AI provides important lessons and insights for practi-
tioners and theorists of participatory methods broadly through
its rejection of hierarchy in favor of decentralization, success at
building aid and programs by and for the queer community, and
effort to change actors and institutions outside of the queer com-
munity. Finally, we theorize how communities like Queer in AI
contribute to the participatory design in AI more broadly by fos-
tering cultures of participation in AI, welcoming and empowering
marginalized participants, critiquing poor or exploitative participa-
tory practices, and bringing participation to institutions outside of
individual research projects. Queer in AI’s work serves as a case
study of grassroots activism and participatory methods within AI,
demonstrating the potential of community-led participatory meth-
ods and intersectional praxis, while also providing challenges, case
studies, and nuanced insights to researchers developing and using
participatory methods.
ACM Reference Format:
Organizers of QueerInAI, Anaelia Ovalle, Arjun Subramonian, Ashwin
Singh, Claas Voelcker, Danica J. Sutherland, Davide Locatelli, Eva Breznik,
Filip Klubička, Hang Yuan, Hetvi J, Huan Zhang, Jaidev Shriram, Kruno
Lehman, Luca Soldaini, Maarten Sap, Marc Peter Deisenroth, Maria Leonor
Pacheco, Maria Ryskina, Martin Mundt, Milind Agarwal, Nyx McLean, Pan
Xu, A Pranav, Raj Korpan, Ruchira Ray, Sarah Mathew, Sarthak Arora, ST
John, Tanvi Anand, Vishakha Agrawal, William Agnew, Yanan Long, Zijie J.
Wang, Zeerak Talat, Avijit Ghosh, Nathaniel Dennler, Michael Noseworthy,
1883
Queer In AI: A Case Study in Community-Led Participatory AI FAccT ’23, June 12–15, 2023, Chicago, IL, USA
Sharvani Jha, Emi Baylor, Aditya Joshi, Natalia Y. Bilenko, Andrew McNa-
mara, Raphael Gontijo-Lopes, Alex Markham, Evyn D ˇong, Jackie Kay, Manu
Saraswat, Nikhil Vytla, and Luke Stark. 2023. Queer In AI: A Case Study in
Community-Led Participatory AI. In 2023 ACM Conference on Fairness, Ac-
countability, and Transparency (FAccT ’23), June 12–15, 2023, Chicago, IL, USA.
ACM, New York, NY, USA, 14 pages. https://doi.org/10.1145/3593013.3594134
1 INTRODUCTION
Artificial intelligence (AI) has seen enormous developments in re-
cent years, such as substantial advances in protein modeling, drug
discovery, weather prediction, and personalized medicine [ 67,102,
128]. The ubiquity of unregulated AI within socio-technical sys-
tems, however, often produces discriminatory outcomes and harms
marginalized communities globally [ 8,10,66]. For queer people in
particular, machine learning models learn brittle, toxic represen-
tations that cause representational and allocational harms, from
misgendering to healthcare discrimination [ 32,37,70,124]. Identi-
fying and mitigating harmful outcomes has led to the development
of computational and socio-technical methods for achieving fair-
ness [ 13,29,86], including automatic evaluation and unfairness
mitigation techniques [ 16,41,86]. While such approaches have
the potential to mitigate harms for queer people in domains like
fighting online abuse, health, and employment [ 124], computa-
tional techniques generally encode narrow conceptualizations of
fairness where queer identities are assumed to be known, observ-
able, measurable, discrete, and static [ 81]. By locating the source of
unfairness in individuals or in specific design decisions [ 129], com-
putational approaches to fairness can reinforce existing power rela-
tions [ 35,68], including marginalized communities only in preda-
tory ways [ 53] or as “ethics washing” [ 112] (cf. Appendix §A for
an extended critique of computational approaches to fairness).
Participatory methods address some of these limitations. Involv-
ing users as co-designers holds great potential for dismantling
power relations and empowering marginalized communities that
are disproportionately impacted by AI [ 9,74,119]. Reflexivity in
participatory methods encourages transparency during the design
process itself, as opposed to a detrimental “innovate first, fix later”
approach to building trustworthy AI [ 48]. By establishing the value-
laden nature of technologies, it can prevent personal biases, beliefs
and values from seeping into AI systems unexamined.
Unfortunately, there are many challenges to incorporating par-
ticipatory approaches across top-down structures, such as corpora-
tions that operate within capitalism. Popular modes of participation
within AI suffer from extractive and exploitative forms of commu-
nity involvement or “participation washing” [ 112]. For example,
a recent report [ 95] sheds light on how OpenAI used exploitative
labor practices to make ChatGPT less toxic, subjecting Kenyan
workers to psychologically distressing content1without sufficient
provision for mental health support. Gray and Suri [56] also uncov-
ers many exploitative labor practices performed by minorities to
power AI systems.
More fundamentally, we question whether marginalized com-
munities should engage in designing with the creators of harmful
AI systems that prioritize profit over their safety. Even in projects
where communities are involved, engagement is too often limited
1This content included examples of sexual abuse, hate speech, violence, murder, child
abuse, rape, animal abuse, torture and self-harm.in scope and time. Contrary to participation being controlled by
the corporations and states the design and own AI, we argue in the
favor of shifting power towards marginalized groups and centering
their experiences. We call for a culture of participation in AI to
address this, one that enables deep and long-term participation in
AI research, institutions, and practices.
Over the years, the AI community has witnessed several
community-led efforts from marginalized communities, each
tackling issues of inequality that arise along various axes of
marginalization; these include Black in AI [ 12], LatinX in AI [ 77],
Women in Machine Learning [ 133], Masakhane [ 84], Widening
NLP [ 130], Diversity in AI [ 36], Indigenous in AI [ 64], Queer in
HCI [ 34], the Indigenous Protocol and AI Working Group [ 79], the
Deep Learning Indaba [ 31], Khipu [ 73], North Africans in ML [ 91],
{Dis}Ability in AI [ 63], Te Hiku Media [ 47], and Muslims in ML [ 88].
These organizations have worked in AI ethics, advocated against
AI harms, provided longstanding venues and visibility for AI
ethics research within major ML and NLP conferences, resolved
inclusion issues with those venues, and developed community-led
datasets, models, and other technology. Most importantly, they
have advanced participation by marginalized communities in AI
research and development at large, nurturing countless researchers
and practitioners with community, mentorship, financial aid,
and innumerable other forms of help with the many barriers
marginalized people face in AI. These groups have made AI much
more diverse, and strengthened the voices of marginalized people
within AI.
In this work, we argue that AI ethicists who value participatory
methods as a means for making ethical AI should engage with par-
ticipatory and community-lead AI ethics organizations, and study
their organizational, strategic, and administrative work through
which they are advancing participation and building cultures of
participation. This often difficult process involves navigating the
complexities of combining inquiry with praxis, and sheds light on
differences between participatory approaches.
To this end, we offer a case study analyzing Queer in AI, a grass-
roots organization that aims to raise awareness of queer issues in
AI/ML, foster a community of queer researchers and celebrate the
work of queer scientists. Operating primarily as an online com-
munity over Slack, the organization runs various programs and
initiatives towards fulfilling its mission. We analyze and critique
its principles, methodology, initiatives, and impact over the years
as a case study of community-led participatory methods in AI.
Our key contributions are:
•We document salient forms of marginalization and oppres-
sion that particularly affect queer people (§2).
•We present the organizing principles and programs of Queer
in AI (§3), including how they started, major changes, and
qualitative and quantitative analyses of impacts (§4).
•We analyze challenges and shortcomings of Queer in AI (§5).
•We present an argument for conducting more and valuing
AI ethics research that combines inquiry and praxis (§6).
Positionality Statement Most authors of this paper are formally
trained as computer scientists, with some also having training in
gender theory or related fields. All authors have informal training
in queer studies through activism and advocacy. Our backgrounds
1884
FAccT ’23, June 12–15, 2023, Chicago, IL, USA Organizers of Queer in AI, et al.
Community ResponseGraduate School Application
Financial Aid Program
Inclusive Conference
Guide
Trans-Inclusive Publishing
AdvocacyWorkshops
& Socials
Tensions and ChallengesHierarchy Accessibility
Funding
Core PrinciplesDecentralized
OrganizingIntersectionality
Community-Led
Initiatives
OutcomesEquity Inclusivity
Community Role Models
Figure 1: Overview of Queer in AI’s core principles, community responses, programming outcomes, and tensions and challenges.
influence this work’s design, decisions, and development. We do
our best to position our work in a global context, with authors from
Asia, Europe, South Africa, South America, and North America.
2 MARGINALIZATION OF QUEER PEOPLE IN
STEM AND AI
Hegemonic forms of AI focus on classifying complex people and
situations into narrow categories at the cost of context, and are
often built to support surveillance, prediction, and control – de-
signs which are fundamentally incompatible with queer identi-
ties rooted in the freedom of being [ 71]. The framing and use of
common AI systems that interact with gender are thus often prob-
lematic, and inherently cisnormative and heteronormative, so that
even well-meaning, purportedly inclusive AI projects are prone
to “designing out” certain queer lives [ 59]. Documented harms
across various AI applications are numerous, and sometimes life-
threatening. These include physiognomic and phrenologic appli-
cations such as computer vision to (falsely) infer gender and sexu-
ality [ 4,70,72,80,107,108,118]. AI-enabled surveillance systems,
in conjunction with surveillance of online spaces such as dating
apps by states, corporations, and even individuals have outed queer
people, compromising their privacy and safety [ 22,61,92,94]. On-
line spaces, especially social media platforms, have insufficient
and poorly explained privacy and security tools, requiring com-
munity education and adaptation to meet the needs of queer peo-
ple [33,54,96]. Their moderation enables widespread censorship
of queer words and identities [ 30,43,111,113], while also sub-
jecting queer communities to disproportionate online harassment
and hate speech [ 97,125]. Some of these harms can be traced to
large language models (LLMs) trained on datasets containing hate
speech and censored queer words, leading search systems to avoid
queer content and content moderation systems to more often tag it
as suspect [ 37,55]. LLMs also overwhelmingly fail to account for
non-binary genders and pronouns, contributing to erasure of these
identities [17, 32].
In the US, queer people are (at least) 20% less represented in
STEM than in the national population, and experience higher lev-
els of “career limitations, harassment, and professional devalua-
tion” [ 19]. Consequently, queer scientists often face “systematically
more negative workplace experiences than their non-LGBT col-
leagues” [ 20], and “leave STEM at an alarming rate” [ 51]. The
exclusion of queer people from science comes with significant
consequences, both for queer scientists and queer people further
marginalized by fields that do not understand or care about them.The medical profession’s response to the HIV/AIDS crisis was fa-
tally slow until pressured by heroic activism [ 110]; a medical field
that had included and empowered queer people may have saved
many queer lives. Similarly, the American Psychiatric Association
classified homosexuality as a mental illness until 1973, greatly con-
tributing to the stigmatization of queer people around the world,
until queer activists pressured the group for change [ 38]. Recent ini-
tiatives have inverted this dynamics, centering queer communities
in descisions about mental healthcare [74].
One hurdle in understanding the marginalization of LGBTQIA+
people in STEM is a lack of demographic data on sexual orientation
and gender identity [ 51]. The US’s National Science Foundation has
delayed the collection of such data for years, despite the urging of
queer scientists [ 76]. Taking matters into its own hands, Queer in AI
administers an annual survey of its global community to uncover
the demographics and challenges faced by queer researchers in
AI (discussed in detail in Appendix §B). In Queer in AI’s 2021-22
community survey ( 𝑁=252), 74% of members reported a lack of
role models and 77% reported a lack of community as obstacles in
their journey of becoming an AI practitioner.
There is a dire lack of studies and data on queer scientists’ ex-
periences in the Global South, where colonial histories have led
to the criminalization of queerness [ 1–3]. Queer in AI organizers
from Turkey, Colombia, and India have shared that much queer
activism in these countries focuses on survival and gaining basic
human rights, recognition and respect in society, amid high levels
of discrimination, violence, and psychological distress [ 23]. They
perceive being out and working towards queer visibility in STEM
fields to be beyond luxuries, especially given the dominant (cisnor-
mative, heteronormative) view that identity and profession should
be “kept separate.” Barriers to acceptance are only amplified for
queer individuals also marginalized on intersecting axes like class
or caste.
3 CORE PRINCIPLES OF QUEER IN AI
Three governing principles drive Queer in AI’s mission to raise
awareness of queer issues in AI and foster a community of queer
researchers: (i) decentralized organizing, (ii) intersectionality, and
(iii) community-led initiatives. Overall, Queer in AI’s decentralized
operations allow for swift community-led initiatives towards its
mission (§3.1), which center on intersectionality as critical inquiry
and praxis (§3.2). In doing so, it acknowledges and continuously
works to account for “the complexities of multiple, competing, fluid,
and intersecting identities” [ 58]. Queer in AI’s primary approach
1885
Queer In AI: A Case Study in Community-Led Participatory AI FAccT ’23, June 12–15, 2023, Chicago, IL, USA
consists of including people with diverse lived experiences in par-
ticipatory schemes (§3.3).
3.1 Participation and Decentralization
For its first two years, Queer in AI had a hierarchical structure,
with a president and officers. However, organizing and governance
of grassroots communities, and especially queer communities,
presents unique challenges. Queer people are incredibly diverse,
and choosing one or even a group of queer people to represent
the community as a whole is reductive and impossible. This is also
difficult for the organizers, with high-profile queer activists and
organizers frequently facing targeted harassment campaigns, and
Queer in AI organizers frequently reporting lack of time, external
support, or recognition for volunteering (cf. Figure A16). Queer in
AI thus adopted a decentralized organizing structure, to encourage
broad participation. Queer in AI minimizes distinctions between
organizers and members to encourage the entire community to
participate in organizing. Most volunteer coordination occurs
in the same Slack channel as is used for community discussion,
calls for help or feedback on programs mixed with memes,
introductions, personal news, and discussions of travel or pets. Of
the 49 active Slack channels only 4, where personally identifiable
information is discussed, are not public. Openness and embedding
in the community increase transparency and accountability: any
community member can view organizing discussions and join
in, with no more barrier to entry than joining a Slack channel.
It also helps provide the connection and joy for which 75%
of its organizers joined Queer in AI (cf. Figure A15). Fluidity
between member and organizer also makes it easier for community
members’ areas and levels of engagement to ebb and flow over
time without losing their connection to the community.
3.2 Participation and Intersectionality
Over five years, Queer in AI’s community has grown to about 870
members, geographically distributed across more than 47 coun-
tries (cf. Figure 2). The community members have diverse identities
across axes such as ethnicity, gender, class, disability, and caste.
About 20.3% of respondents identified as transgender, and 34.4%
identified as non-cisgender; 34.9% identified as Black, Latinx, in-
digenous or a person of color; less than 2% identified as intersex.
Membership spans academia and industry, with about 16% of mem-
bers pursuing an undergraduate degree, 21% in an industry role,
and 64% in academia, all with varying degrees of seniority (cf. Ap-
pendix §B.6 for additional details of community demographics). As
a result, Queer in AI helps naturally bridge otherwise insular aisles
of power and social contexts.
As the queer community consistently experiences discrimina-
tion, stigmatization, and inequity [ 18,87], Queer in AI uses the
lens of intersectionality as a means of critical inquiry to identify
how interlocking forms of oppression, such as racism and sexism,
co-construct and exacerbate social and structural disparities [ 26].
To proactively dismantle injustices, Queer in AI centers the experi-
ences of its members so that active participation in the Queer in AI
community results in the co-creation of initiatives, which reflect
of tackling such barriers, including economic (§5.3), educational
(§4.1), and social (§4.2) ones. By prioritizing fighting intersectionaloppression, Queer in AI attempts to empower its most marginalized
members to shape and control its programming, addressing key
challenges of participatory design such as the exclusion of marginal-
ized people from participation [ 69], community power-sharing [ 27]
and the co-formation of knowledge [ 45]. In doing so, Queer in AI
works towards a system of resistant knowledge firmly grounded in
intersectionality’s critical praxis [25, Chs. 3 & 4].
3.3 Participation and Community Leadership
3.3.1 Research. Various forms of community-engaged research
guide the dissemination of knowledge both within and outside
of Queer in AI and exist across a continuum, from community-
informed to community-involved to community-led. Community-
informed research consists of researchers inviting the community
to incorporate lived experience to guide research questions, data
collection, or data interpretation [ 60]. Towards more community-
involved research, community members may be more involved
in decision-making processes and research planning [ 60,105]. At
the highest level of engagement, community-driven approaches
such as community-based participatory action research (PAR) cen-
ters shared collaborative decision-making between researchers and
community members across research design, knowledge creation,
intervention development, and policy-making [ 28,82,126]. In prac-
tice, entities outside of the organization may partner with Queer
in AI community members to form relationships designed to help
objectives oriented towards investigating and supporting “the pur-
suit of answers to the questions of their daily struggle and survival”
[121]. Individuals are often members of both other entities as well
as of Queer in AI so that members may operate from the role of
an external entity (e.g. researcher from a company) and at vari-
ous depths of community engagement. The resulting knowledge
production is such that is “by the people, for the people” in which
research is not only seen as a process to create knowledge but
to also educate and mobilize for action [ 28,57]. By “putting com-
munity first”, the distinction between participant and researcher
is removed. Community-based participatory action research thus
also serves as a decolonizing epistemological framework which
inherently interrogates power and privilege [46].
3.3.2 Response & resilience. Within Queer in AI, community re-
silience operates across dimensions including but not limited to the
social, political, and economic. Advocacy efforts operate across do-
mains, tasks, resources, and activities within the organization [ 75].
Resources and activities are structural means towards tasks and
domains that reflect the Queer in AI mission. Specifically, resources
and activities are dedicated to raising awareness of queer issues in
AI/ML. Financial, educational, and social avenues are created within
the organization as a form of creating resilience and advocacy in
the face of oppressive sociotechnical barriers. Operating across 47
countries, Queer in AI primarily organizes through Slack, Zoom, a
dedicated mailing list, and social media platforms. Doing so makes
room for rapid and adaptive situational awareness within the online
community [ 117]. Besides the “internal” milieu of an organization,
Queer in AI is responsive to events in both reactive and proactive
forms. Digital volunteer efforts emerge as self-organizing responses
to external factors [ 24,42]. This work further details examples of
1886
FAccT ’23, June 12–15, 2023, Chicago, IL, USA Organizers of Queer in AI, et al.
Figure 2: Country of origin of the respondents to the Queer in AI’s 2021–2022 demographic survey.
Table 1: Self-reported ethnicity, gender, and sexual orientation of the respondents to the Queer in AI’s 2021–2022 demographic
survey. Write-in responses were aggregated by a team of Queer in AI organizers, with some falling into multiple categories (cf.
Figure A4). “Unaggregated” refers to responses that could not be adequately described with any subset of other categories;
however, responses in this group may overlap with the remaining categories. For options with fewer than 4 responses, exact
values are omitted for privacy.
Ethnicity Gender Sexual Orientation
Caucasian 127 Man 108 Queer 90
South Asian 34 Woman 95 Gay 89
East Asian 17 Non-binary 61 Bisexual 87
Black/African/African-American 13 Genderqueer 29 Pansexual 42
Latinx 13 Gender non-conforming 22 Lesbian 30
Mixed 12 Genderfluid 19 Asexual 26
Jewish 8 Agender 17 Unaggregated 29
Middle Eastern 8 Questioning 16
Southeast Asian 6 Unaggregated 16
West Asian ≤3
Central Asian ≤3
Hispanic ≤3
Unaggregated 6
how responses to acute external factors and larger efforts against
oppression manifest as Queer in AI initiatives.
4 QUEER IN AI INITIATIVES
The structure of Queer in AI is decentralized and includes volun-
teers, core organizers (extensive organizing experience with Queer
in AI) and a diversity, equity and inclusion admin (DEIA, a core
organizer who has a more active role in administrative duties). Most
of Queer in AI’s communication is mediated by its Slack workspace.
A key aspect of Queer in AI’s organizing lies in the transparency
of its operations and associated information exchanges, which pre-
dominantly take place over public Slack channels. There are only
four private channels on the workspace, which exist to preserve
privacy while facilitating discussions around personally identifi-
able information. The workspace has included the exchange of
over 133,000 messages (including individuals’ one-to-one private
messages), of which over 25,000 have been sent in public channels,
accounting for the majority (57%) of total views. This transparency,
in conjunction with regular updates and outreach on Slack, keeps
community members involved in ongoing events and initiatives.Many of Queer in AI’s initiatives have emerged from conversa-
tions and threads on public channels about discriminatory experi-
ences with different institutions. For example, discussion around
exclusionary gender collection practices on conference registration
forms led to the creation of an inclusive conference guide (covered
in more detail in §4.3) and substantial improvements to relevant
conferences’ practices. Similarly, significant advocacy against dead-
naming in citations and conference proceedings (§4.4) began from
discourse on public channels. Thus, as a space, Queer in AI’s Slack is
effective at mobilizing community-led initiatives through decentral-
ized organizing. Moreover, the emergence of these initiatives from
diverse yet intersecting shared queer experiences grounds them
in global contexts of social inequality and injustice. For instance,
Queer in AI’s graduate school application financial aid program
(§4.1) and workshops and socials (§4.2) target several particular
challenges rooted in non-Western contexts, centering otherwise-
marginalized experiences. The organizational and volunteer work
that constitutes the administration of all these initiatives is thus
deeply intersectional.
1887
Queer In AI: A Case Study in Community-Led Participatory AI FAccT ’23, June 12–15, 2023, Chicago, IL, USA
We now examine four major initiatives in detail; Appendix §C
further describes efforts in policy advocacy.
4.1 Graduate School Application Financial Aid
Program
Queer folks report a lack of community and queer role models due
to the underrepresentation of senior queer folks in academia. Thus,
supporting queer and low-income scholars financially helps bring
more marginalized voices into STEM academia, creating more op-
portunities for participatory research and technology design. To
address this, Queer in AI launched the Graduate School Applica-
tion Fee Aid Program to improve queer representation and make
graduate programs accessible.
4.1.1 Financial challenges. The costs for graduate school applica-
tions prevent many low-income and international scientists from
accessing graduate programs, well before they can benefit from
many of the fellowships and need-based scholarships intended to
address exclusion. This process is costly: between the application
fees (∼$50–$150 USD per program in North America and parts of
Europe), costs of required tests (e.g. GRE), test results and tran-
script delivery fees, and test preparation expenses, one round of
applications can easily amount to over $1,000 USD. International
applicants may be further required to pay for language proficiency
tests (e.g. TOEFL), translation services, and third-party credential
vetting. Although some schools offer fee waivers, they vary widely
from school to school, are often very limited in applicability, and
can require onerous documentation.
The majority of applicants apply to North American schools.
This is likely caused by the cultural dominance of Anglo-American
schools in the AI/ML space and the common practice of requiring
extensive standardized tests and application fees at these schools.2
Standardized tests like the GRE claim to level the playing field for
applicants, they institute barriers to individuals from the Global
South and reify colonialism under a veneer of fairness. Addition-
ally, fees make these exams wholly inaccessible to many in the
Global South: the GRE costs three times the average monthly salary
in Ethiopia [ 11]. Data collected from Queer in AI’s surveys have
been used to argue that departments should eliminate the GRE and
application fees.
These financial challenges are particularly likely to be insur-
mountable for queer scientists, who may be cut off from familial
financial support, might pay out of pocket for gender-affirming
healthcare, and often incur additional expenses managing oppres-
sion and trauma. Queer people thus suffer from increased student
loan debt [ 83] and high rates of housing insecurity [ 131]. A com-
plete critique of the graduate application process and its socio-
economical context is out of the scope of this paper. Queer in AI
believes it is nonetheless important to provide concrete aid right
now to applicants faced with the current system.
4.1.2 Mutual aid design. The design of the aid program is decentral-
ized, community-led constituting volunteers with a diverse range
2While fees and standardized tests are the norms at many prominent institutions,
there are examples of alternative paths, such as the ELLIS PhD Program, a European
initiative for AI/ML PhD programs, which requires neither [44].of experiences with graduate school admissions [ 114]. This initia-
tive keeps minimum barriers to receiving the aid by not seeking
to decide who is “deserving” of aid, avoiding imposing excessive
requirements for documenting eligibility and providing timely men-
torship and help to the applicants for their submissions. Although,
the payment pipeline often disadvantages applicants from coun-
tries and territories where PayPal is not available or restrictions
are imposed on receiving transfers from the US.
4.1.3 Participatory learnings. Each aid applicant is treated as a
member of the community with a valuable perspective of their
own – the initiative actively seeks feedback from aid recipients
and encourages them to volunteer in the future, which would both
help improve the program and keep it sustainable. This feedback
indicated that aid recipients’ demographics were more diverse than
Queer in AI’s organizing team (Table 3), which helps Queer in AI
recruit more diverse volunteers and community members by first
directly, meaningfully helping them. Also, the feedback survey il-
lustrates widespread deficiencies in existing admissions fee waivers:
such as lack of fee waivers (67%), unable to produce adequate docu-
mentation (14%) and the fear of outing themselves (10%). This aid
program allowed recipients to take admissions tests (56%), avoid
skipping essential expenses (54%) and avoid skipping groceries or
bills (40%). The vast majority of recipients reported the scholar-
ship enabled them to apply to additional programs (around 6 on
average).
4.1.4 Critical Reflections. The program operates with a tension
between opening opportunities to marginalized people from all
over the world and reinforcing the exclusionary practices of these
powerful institutions. In addition to funding influential and rich
academic institutions, the program also indirectly supports the
standardized testing industry. The limited amount of funds and
barriers to sending the money internationally often pose challenges
between the organizers and the aid recipients. In spite of that, Queer
in AI believes that it is crucial to provide timely aid regardless of
these barriers, even if doing so reinforces undesirable structures.
4.2 Workshops and Socials
In STEM disciplines, conferences can be a hostile setting for minori-
tized groups [ 85,104,134]. Queer in AI members in 2022 rated how
welcome they felt attending AI conferences at 3.38 on average ( 𝜇1/2
= 3) on a five-point Likert scale (cf. Appendix § B). Recognizing
this need, Queer in AI has organized workshops and networking
events since its very first informal meetup at NeurIPS 2017: as of
submission, 13 workshops and 35 social events in total (Table 4),
with a cumulative attendance of hundreds of participants.3These
events provide an opportunity to connect and network with other
queer scientists, spotlight work by members of Queer in AI, host
talks on topics relevant to its members, and arrange panels where
experts discuss topics at the intersection of AI, fairness, ethics, and
the queer community. The following subsections cover how Queer
in AI’s principles influence event planning and enable them to
overcome challenges in the process.
3An exact count could not be obtained: to maintain attendees’ privacy, Queer in AI
does not require signups for most events, and deletes names immediately after events
when they are required.
1888
FAccT ’23, June 12–15, 2023, Chicago, IL, USA Organizers of Queer in AI, et al.
Table 2: The Queer in AI Graduate School Application Fee Aid Program budget and impact per academic year, in USD.
Academic year Aid per applicant No. aid recipients Total aid Budget
2020/2021 up to $750 31 $16,689 $20,000
2021/2022 up to $1,250 81 $70,607 $73,768
2022/2023 (at time of writing) up to $1,250 48 $40,476 $41,711
Table 3: Gender, sexual orientation, romantic orientation and continent of scholarship recipients who filled the optional
feedback survey ( 𝑛=46out of 𝑁=160total recipients). For options with fewer than 4 responses, exact values are omitted for
privacy.
Gender Sexual Orientation Romantic Orientation Continent
Woman 20 Gay 18 Homoromantic 21 Asia 19
Man 18 Queer 16 Biromantic 13 North America 14
Genderqueer 7 Bisexual 12 Demiromantic 5 Africa 5
Non-binary 6 Lesbian 9 Grayromatic 5 Europe ≤3
Gender non-conforming 6 Asexual 4 Alloromantic ≤3 South America ≤3
Agender ≤3 Pansexual 4 Aromantic ≤3
Genderfluid ≤3 Demisexual ≤3 Heteroromantic ≤3
Questioning ≤3 Questioning ≤3
Table 4: Workshop and events organized by Queer in AI in 2017–2022 across conferences in AI. Events marked with pwere held
in person, vindicates virtual-only events, and hrefers to events that occurred in a “hybrid” format.
Year 2017 2018 2019 2020 2021 2022
Workshops -1
NeurIPSp2
ICMLpNeurIPSp2
NeurIPSvICMLv3
EMNLPv†ICMLvNeurIPSv5
FAccTh‡ICLRvICMLh
NAACLhNeurIPSh
Social Events1
NeurIPSp1
NeurIPSp5
ACLpCVPRpICMLp
NAACLpNeurIPSp11
AAAIpAACLvACLvCogSciv
COLINGvCORLvEMNLPvFAccTp
ICLRvICMLvNeurIPSv10
AAAIvACLvCoRLvEACLv
EMNLPvICLRvICMLvNAACLv
NeurIPSvSIGIRv7
AAAIvAAMASvACLhICLRv
ICMLhNAACLhNeurIPSh
†at EMNLP 2021, Queer in AI co-hosted a workshop with WiNLP.
‡at FAccT, Queer in AI hosted two CRAFT sessions.
4.2.1 Workshop Organizing. Queer in AI workshops and socials
are typically organized by members of the community planning
to attend the conference; no prior academic or organizing expe-
rience is required. Junior or new members of the community are
often encouraged to lead these initiatives while being mentored by
more experienced organizers throughout the process. Organizers,
DEIAs, and Queer in AI’s financial stewards coordinate to secure
logistical, monetary and other miscellaneous needs of the event.
These include renting equipment to support accessibility, honoraria
for speakers, scholarships for attendees, refreshments for socials,
online outreach and promotion of the event, and so on. All of this
communication takes place asynchronously over Slack, or in Zoom
meetings scheduled across organizers’ time zones. This decentral-
ized approach also helps enable Queer in AI members spanning
different sub-fields in AI to tailor events to represent and serve
the needs of their sub-community. When prompted to rate how
welcome they felt at these workshops, the response was overwhelm-
ingly positive, with about 47% of queer attendees rating it five out
of five on a Likert scale ( 𝜇=4.16, 𝜇1/2=4) (cf. Appendix § B6).
4.2.2 Panels and Talks at Workshops. Panels and talks at Queer in
AI are crucial as they help in amplifying queer voices and concerns
in our field. Many topics presented in the panels and keynotes have
later served a bigger impact in the AI field, such as talks on confer-
ence inclusivity and name change policies. Queer in AI encourages
a participatory approach to workshop design: by soliciting topicsand speaker ideas from community workspace. This approach has
allowed Queer in AI to host panels and talks on intersectional topics
that often do not have a presence at major AI/ML venues (for just
one example, a discussion on the intersection of queerness, caste
and AI at NeurIPS 2021 [ 99]). Queer in AI organizers spend tremen-
dous effort by making the workshops as inclusive as possible by
providing fair honoraria to the speakers and organizing the events
in online, hybrid, and in-person settings.
4.2.3 Barriers and Challenges in Participation. AI conferences are
often not accessible for a sizable portion of queer researchers, espe-
cially those belonging to other marginalized backgrounds or from
countries with lower purchasing power or higher rates of discrimi-
nation towards queer people [ 127]. Primary reasons includes high
registration and travel costs. Out of all Queer in AI members who
reported being unable to attend conferences owing to lack of fund-
ing, 88% identified as one of black, indigenous, person of color,
transgender, neurodivergent, or disabled (cf. Appendix § B6). While
Queer in AI tries to work with conference organizers to use DEI
funds for increasing the attendance of queer scientists, in many
cases conference organizers refuse to engage with Queer in AI’s
requests. Queer in AI thus often provides a combination of travel
grants, registration waivers, and reimbursement for conference-
related expenses to queer AI researchers. In other cases, unofficial
1889
Queer In AI: A Case Study in Community-Led Participatory AI FAccT ’23, June 12–15, 2023, Chicago, IL, USA
social events4near the conference venue and online virtual so-
cials on gather.town are organized to accommodate excluded time
zones and overcome both financial and geographical access barriers.
Other barriers specific to the conference location, such as unsafe
legal and social climates5for queer people or exclusionary visa
processes, continue to significantly limit queer participation within
AI spaces. Finally, for conferences which are poorly equipped in
their support for disabled people, Queer in AI provides live captions
for all in-person and virtual events, and secures equipment to create
accessible spaces.
4.3 Advocacy for Improving Queer Inclusivity
in Conferences
As conferences moved online in response to the COVID-19 pan-
demic, Queer in AI organizers noted a series of operational failures
that could cause queer attendees to feel unsafe or unwelcome. Regis-
tration platforms demanded attendees to provide their legal names,
thus potentially deadnaming them; the use of pronoun badges for
speakers and attendees was rarely encouraged, or platforms did
not support displaying pronouns; virtual chat software blocked
common queer terms such as “queer” or “lesbian”, thus preventing
queer attendees from communicating freely. Queer in AI organizers
worked closely with many conferences to resolve these issues, as
they had in prior settings (§4.2), and ultimately decided to collect
recommendations aimed at highlighting best practices to ensure
safety, privacy, and accessibility for queer attendees at academic
conferences in AI in a collected guidance document.6
These recommendations began based on existing best practices
and experience with conference organizers, but were refined
through extensive iterative feedback from members of Queer in
AI and other affinity groups, incorporating many opinions and
ultimately achieving consensus among a broad group of contribu-
tors. The guide has recently been expanded to also cover in-person
events as conferences move to hybrid or in-person formats.
This queer advocacy to improve inclusivity covers two aspects:
improving queer safety and increasing queer representation.
4.3.1 Improving Queer Safety: As in any public space, queer
conference-goers might face discrimination based on their gender
and sexual orientation. Therefore, it is paramount for attendees
to be able to control what information they wish to disclose
to the organizers and attendees of a conference. Queer in AI
advocates mechanisms to (i) respect attendees’ identities by
collecting gender and pronoun information in a manner that does
not misrepresent or erase queer identities, by creating forms with
inclusive gender categories and disclosing the data usage [ 106] (ii)
minimize the amount of personal information queer individuals
have to disclose [ 7] (for example, only collecting legal names
when absolutely necessary, and using responses about the gender
4These events are not officially included within the conference program but promoted
over Queer in AI’s Slack and mailing list as well as social media. A recent example is
AAAI 2023 where the conference fees was exorbitantly high and negligible effort was
put into provision for registration waivers.
5EMNLP 2022 (in Abu Dhabi) predatorily included Queer in AI to obtain their approval
for conference safety measures; Queer in AI rejected this, due to the conference
operating at a different domain of power for trans people and the power inherent in
speaking for the entire queer community.
6The guide, originally published as [ 101], is a living document available at
queerinai.com/how-to-make-virtual-conferences-queer-friendly.and sexuality of attendees only for statistical purposes and in
anonymized form); and (iii) ensure that mechanisms to report
disruptive or harmful behaviours are swift and effective. Queer in
AI recommends adopting a code of conduct ( e.g., [100,132]) to not
only establish communication norms, but also describe how policy
violations are handled [39].
4.3.2 Increasing Queer Representation and Participation: Queer re-
searchers’ needs are regularly ignored in many aspects of the re-
search community: challenges include lack of academic support,
hostility from colleagues and advisors, inflexible name change poli-
cies, lack of representation in the research itself, and more [ 21].
Stronger inclusion efforts, both for representation and participa-
tion, can work towards addressing a lack of queer community and
role models [ 109]. To increase representation, Queer in AI strongly
encourages conference organizers to invite queer keynote speakers
and panelists, prioritizing those from marginalized backgrounds
(e.g., BIPOC or non-cisgender) [ 40]. Queer in AI recommends fair
and equal compensation based on effort rather than seniority for
all speakers [ 52,103]. As noted in previous sections, financial acces-
sibility and a lack of community were the main barriers for queer
folks to feel included at conferences. Queer in AI strongly advocates
setting up spaces for queer folks to network and socialize with pri-
vacy measures and also providing subsidies for queer researchers
to attend virtual or in-person events.
4.3.3 Critical Reflection. This guide and advocacy are not without
their limitations. Most recommendations are still focused on vir-
tual spaces and currently written guide lacks in-depth accessibility
recommendations. Queer in AI needs to collaborate with disabled
folks with a wider range of disabilities to document best practices
regarding accessibility accommodations. Most significantly, despite
organizers’ efforts the guide has seen relatively modest adoption.
4.4 Trans-inclusive Publishing Advocacy
For many transgender, non-binary, and gender-diverse scholars
(as well as others), the continued circulation of a previous name
in publishing is a significant source of trauma [ 122]. Referring to
an author by a previous name without consent (deadnaming) may
effectively out their identity against their will. Queer in AI has
worked along with the Name Change Policy Working Group [ 89]
to advocate name change policies in AI venues, helping to establish
the name-change policies and procedures now adopted by most
AI-related venues [ 5,6,14,15,62,78,90,123] (cf. Appendix § C for
more about Queer in AI’s advocacy and impact).
Even publishers with functional name change policies are often
woefully slow to implement them, and search engines can index
outdated information long after its correction [ 115,116]; moreover,
authors often use outdated bibliographic entries long after relevant
publications and search tools have been updated [ 120]. It is thus
vital to check the correctness of citations in submitted papers to
avoid propagating incorrect information. QueerInAI has thus devel-
oped a tool to check paper PDFs for mistaken citations. It searches
the ACL Anthology, DBLP, and arXiv for a close paper title match,
and prompts a correction if the paper’s author list disagrees with
that source, detecting both deadnaming and incomplete or outdated
1890
FAccT ’23, June 12–15, 2023, Chicago, IL, USA Organizers of Queer in AI, et al.
author lists. DBLP in particular provides better name change sup-
port than many other platforms, via ORCID [ 93]. This toolkit has
been integrated into ACL publication camera-ready systems [ 98],
and Queer in AI hopes to expand it to other conferences. A demo
is available at qinai-name-check.streamlit.app.
Additionally, Queer in AI advocates publishers to promptly grant
name correction requests in any format, without unnecessary bar-
riers or documentation requirements. Such changes should remove
all instances of authors’ previous names from all records, or (at
the author’s discretion) add disclaimers for media that cannot be
updated ( e.g., audio or video recordings). As the result of this ad-
vocacy, Queer in AI has helped institute effective name-change
processes at NAACL and EMNLP; and has worked with the Asso-
ciation for Computational Linguistics [ 49] to implement a name
change process, proactive measures to prevent the deadnaming of
trans authors, and protocols to handle authors’ requests to keep
their videos private.
5 TENSIONS AND CHALLENGES
As reflexivity is a core tenet of intersectionality [ 25], this section
critically examines the tensions and challenges that emerge in the
operationalization of Queer in AI’s principles within its initiatives.
From the issues with Queer in AI initiaitves discussed in the pre-
vious section, we find three common, root themes of hierarchy,
accessibility , and funding . We argue that these are not only criti-
cal challenges for Queer in AI, but deep challengesany participatory
or community-lead AI organization must address to be successful.
5.1 Hierarchy
Decentralized organizing plays a vital role in minimizing power
distance and distinctions between members of Queer in AI. Even so,
there are notable distinctions between members who participate
in organizing, core organizers, and the DEIAs as paid contractors.
Queer in AI’s core organizers and DEIAs help sustain the growth of
the organization through mentorship of new volunteers and institu-
tional memory. In addition, they form a relatively large and diverse
group for deliberating on rare decisons that cannot be discussed
openly, such as those involving PII. Their existence does, however,
pose challenges in accessibility for people unfamiliar with navi-
gating unstructured social networks, and can be non-transparent
to newer or less involved members. The core organizers also as-
sume a more active role, sharing considerable power in steering
the direction of its initiatives. Queer in AI helps address these ten-
sions by setting a fixed one-year tenure for DEIAs, and inducting
organizers who have been active throughout the preceding year
as core organizers. Resolving tensions between decentralization
and hierarchies created by knowledge and experience, or forced
by privacy concerns, nonetheless remains an open problem within
Queer in AI.
5.2 Accessibility
Despite global participation, Queer in AI’s structure and opera-
tional design can discourage participation for many queer scien-
tists. First, participation in a volunteer-run community not only
requires organizers to have income that allows them to perform
free labor but also have access to computers, internet, and otherresources required to even connect with Queer in AI. Second, while
Queer in AI strives to be intersectional, it severely lacks access to
queer networks in countries from the Global South. It originated
and primarily operated within a Western context during its initial
years, which led to the inadvertent creation of barriers that limit
its outreach. For example, because Queer in AI organizers are best
connected with US and European institutions, its events are often
co-located at conferences attended mainly by scientists residing in
the Global North. Further, its meetings often occur at times best
aligned with European and American time zones, at the expense
of much of Asia. Finally, all Queer in AI activities require English
proficiency.
While recent community and focused outreach efforts have re-
duced some of these barriers, significant work lies ahead in estab-
lishing truly global ways of participation, especially for countries
where queerness is criminalized. Third, participation in Queer in
AI exerts a toll on mental health and exhaustion of its organizers
(cf. Figure A16). This is partly due to Queer in AI’s lack of formal
structure, instead relying on individuals self-coordinating on initia-
tives of their choice. While efficient, this approach can make joining
and keeping track of ongoing efforts challenging for newcomers
and neurodivergent members of the community. Past organizers
have also shared anecdotes of experiencing exhaustion, fatigue, and
anxiety due to a lack of accommodation of different working styles
and falling behind on personal schedules while undertaking opera-
tional work for Queer in AI (cf. Figure A16). This disproportionately
impacts disabled and neurodivergent members and is compounded
for intersecting marginalized identities.
Even after years of critical reflection and significant investment
of volunteer time, money, and other resources, Queer in AI is still
inaccessible to many. While accessibility to everyone should always
be the goal, in practice, no single community or participatory initia-
tive will be able to include everyone in that community. Therefore,
participatory researchers aspiring to broad inclusion should con-
sider the pluralities of communities and participatory initiatives
with radically different structures.
5.3 Funding
Funding and payments are where Queer in AI struggles most to
meet its commitments to decentralization, intersectionality, and
community leadership. Queer in AI relies on sponsorships, dona-
tions, and contributions from its parent organization oSTEM to fund
its activities. In 2022, Queer in AI expenses (rounded to the closest
integer) totaled US$100,658: the graduate application fee scholar-
ship program (§4.1) spent $40,435; two DEIA contractors were paid
a total of $33,220; speaker honoraria totaled $14,500; $6,941 went
to travel grants, room and board, and conference registration fees;
emergency microgrants for queer people totaled $5,000. Income
comprised $78,000 in corporate sponsorship, $13,711 in donations,
and $5,000 in grant revenue (cf. Appendix §B.9 provides income
and expenses for previous years.).
Queer in AI’s reliance on corporate sponsorship may call into
question its independence and community-lead ideal. Corporate
sponsors receive access to opt-in resume books, short speaking
opportunities, and event recruiting booths. A large part of Queer
1891
Queer In AI: A Case Study in Community-Led Participatory AI FAccT ’23, June 12–15, 2023, Chicago, IL, USA
in AI’s funding still comes from big tech corporations that are com-
plicit in oppression and genocide globally, such as the policing of
Palestinians. Queer in AI has nonetheless dropped and turned down
many sponsors for ethics concerns, including a mutual decision
with Black in AI in 2021 to drop Google [ 65], costing $20,000 in
lost sponsorship per year. While Queer in AI has been growing
donations, many in the Queer in AI community are students or
early in their careers with very limited capacity to give. Oppor-
tunities for grants are limited, as many scientific funding bodies
such as the US’s NSF exclude queer people from many of their D&I
initiatives [50].
Queer in AI sends honoraria, scholarships, and travel grants to
people in many different countries, primarily through PayPal and
wires. Payment disbursal in Queer in AI is highly centralized; for
reasons of security oSTEM only allows one Queer in AI organizer
to send PayPal payments. All wires and credit card payments must
be sent by the oSTEM CEO. Additionally, payments strain Queer in
AI’s intersectional values. PayPal does not work well in China, In-
dia, many countries in Africa, and some countries in South America,
forcing reliance on slower and more administratively difficult wire
transfers. Moreover, U.S. law requires people receiving honoraria
and other types of payments to pay US taxes above a certain thresh-
old, which requires a lengthy registration process or significant fees
and overhead from Queer in AI. Payments also frequently trigger
spurious fraud alerts and investigations, which require even more
time from and stress on organizers.
In summary, marginalization prefigures Queer in AI’s funding
options, legal and security concerns exert a strong centralizing pres-
sure on financial administration, and the financial system regards
many payments, especially to non-Western countries and those
making them, with suspicion by default.
6 CONCLUSION
Participatory methods have the potential to address issues of power
and inclusion in AI, but their benefits and challenges in practice
are still unclear because few organizations have deeply engaged
with them. In this paper we studied Queer in AI as a case study
of a grassroots participatory AI organization. We explored how
they designed their organization to enable participation, and how
initiatives addressing intersectional marginalization arose from and
were continuously refined by this participation. We theorized how
Queer in AI’s numerous socials, workshops, and other events have
contributed to a culture of participation in AI by bringing queer
people into AI conferences and research and industry settings and
resisting predatory inclusion. We hope this case study will inform
theoretical study and practical design of participatory initiatives. In
particular, we encourage consideration of Queer in AI’s reinforcing
principles of decentralization, community leadership, and focus on
intersectionality, and urge care for mitigating the ways hierarchy,
inaccessability, and funding can subvert participatory methods.
6.1 Future Directions
Queer in AI will continue to grapple with the tensions and alleviate
the challenges addressed in §5. To dismantle hierarchies among
organizers created by knowledge, experienced Queer in AI orga-
nizers will host structured trainings to onboard new organizersonto finance & sponsorships and workshops. Queer in AI addition-
ally plans to supplement its 2023 community survey with commu-
nity interviews about accessibility, towards gleaning actionable
insights about mitigating barriers to participation. Furthermore,
Queer in AI’s organizers will work with its community to refine its
sponsorship policies and identify less precarious mechanisms for
transferring funds. All of these activities are motivated and will be
guided by our core principles of decentralization, intersectionality,
and centering community. Queer in AI will further communicate
its activities and their implications for equity and inclusivity via
accessible media, e.g., blog posts, zines.
ACKNOWLEDGMENTS
This work would not have been possible without the activism and
organizing efforts of the Queer in AI community. We would also
like to thank Katta Spiel and Os Keyes for their insightful feedback
on the earlier versions of the paper.
REFERENCES
[1]2015. Some African Countries Are Trying to Use Science to
Make Homophobic Laws, Now African Scientists are Pushing Back.
https://www.smithsonianmag.com/smart-news/africans-scientists-speak-out-
against-homophobic-laws-180955579/
[2]2020. A constant uneasy state: Trans people in STEM in India. https://
thelifeofscience.com/2020/11/09/transgender-people-in-science/
[3]2022. Brazil LGBTQ activists, HIV/AIDS service providers fear Bolsonaro re-
election. https://www.washingtonblade.com/2022/05/19/brazil-lgbtq-activists-
hiv-aids-service-providers-fear-bolsonaro-reelection/
[4]Blaise Agüera y Arcas, Margaret Mitchell, and Alexander Todorov. 2017. Phys-
iognomy’s New Clothes. https://medium.com/@blaisea/physiognomys-new-
clothes-f2d4b59fdd6a
[5]ACL Anthology. (n.d.). Requesting Corrections. https://aclanthology.org/info/
corrections/ [Accessed Feb 2023].
[6]arXiv. 2021. arXiv Proceedings: Name Change Policy. https://blog.arxiv.org/
2021/03/11/update-name-change-policy, Name Change Policy blog.
[7]Alison Barclay and Melissa Russell. 2017. A guide to LGBTIQ-inclusive data
collection. https://meridianact.org.au. https://meridianact.org.au/wp-content/
uploads/LGBTIQ-Inclusive-Data-Collection-a-Guide.pdf
[8]Emily M Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret
Shmitchell. 2021. On the Dangers of Stochastic Parrots: Can Language Models Be
Too Big?. In Proceedings of the 2021 ACM Conference on Fairness, Accountability,
and Transparency . 610–623.
[9]Abeba Birhane, William Isaac, Vinodkumar Prabhakaran, Mark Diaz,
Madeleine Clare Elish, Iason Gabriel, and Shakir Mohamed. 2022. Power to the
People? Opportunities and Challenges for Participatory AI. In Equity and Access
in Algorithms, Mechanisms, and Optimization (Arlington, VA, USA) (EAAMO ’22) .
Association for Computing Machinery, New York, NY, USA, Article 6, 8 pages.
https://doi.org/10.1145/3551624.3555290
[10] Abeba Birhane, Vinay Uday Prabhu, and Emmanuel Kahembwe. 2021. Mul-
timodal datasets: misogyny, pornography, and malignant stereotypes. arXiv
(2021). https://arxiv.org/abs/2110.01963
[11] Black in AI. 2020. Academic Program. https://blackinai.github.io/#/programs/
academic-program
[12] Black in AI (n.d.). https://blackinai.github.io
[13] Su Lin Blodgett, Solon Barocas, Hal Daumé III, and Hanna Wallach. 2020. Lan-
guage (Technology) is Power: A Critical Survey of “Bias” in NLP. In Proceed-
ings of the 58th Annual Meeting of the Association for Computational Linguis-
tics. Association for Computational Linguistics, Online, 5454–5476. https:
//doi.org/10.18653/v1/2020.acl-main.485
[14] ACM Publications Board. 2019. ACM Publications Policy on Author Name
Changes. https://www.acm.org/publications/policies/author-name-changes
[15] Melisa Bok. 2022. Comment on issue: Transphobic name and email policy. https:
//github.com/openreview/openreview/issues/28#issuecomment-1124245541
[16] Tolga Bolukbasi, Kai-Wei Chang, James Y. Zou, Venkatesh Saligrama, and
Adam Tauman Kalai. 2016. Man is to Computer Programmer as Woman is
to Homemaker? Debiasing Word Embeddings. Advances in Neural Information
Processing Systems 29 (2016).
[17] Yang Trista Cao and Hal Daumé III. 2020. Toward Gender-Inclusive Coreference
Resolution. In Proceedings of the 58th Annual Meeting of the Association for
1892
FAccT ’23, June 12–15, 2023, Chicago, IL, USA Organizers of Queer in AI, et al.
Computational Linguistics . Association for Computational Linguistics, Online,
4568–4595. https://doi.org/10.18653/v1/2020.acl-main.418
[18] Logan S Casey, Sari L Reisner, Mary G Findling, Robert J Blendon, John M
Benson, Justin M Sayde, and Carolyn Miller. 2019. Discrimination in the United
States: Experiences of lesbian, gay, bisexual, transgender, and queer Americans.
Health services research 54 (2019), 1454–1466.
[19] EA Cech and TJ Waidzunas. 2021. Systemic inequalities for LGBTQ professionals
in STEM. Science advances 7, 3 (2021), eabe0933.
[20] Erin A. Cech and Michelle Pham. 2017. Queer in STEM Organizations: Work-
place Disadvantages for LGBT Employees in STEM Related Federal Agencies.
The Social Sciences 6 (2017), 12.
[21] Erin A. Cech and Michelle V. Pham. 2017. Queer in STEM Organizations: Work-
place Disadvantages for LGBT Employees in STEM Related Federal Agencies.
Social Sciences 6, 1 (2017). https://doi.org/10.3390/socsci6010012
[22] Pia Ceres. 2022. Kids are back in classrooms and laptops are still spying on
them. Wired (Aug 2022). https://www.wired.com/story/student-monitoring-
software-privacy-in-schools/
[23] Soon Kyu Choi, Shahrzad Divsalar, Jennifer Flórez-Donado, Krystal Kit-
tle, Andy Lin, Ilan H. Meyer, and Prince Torres-Salazar. 2019. STRESS,
HEALTH, AND WELL-BEING OF LGBT PEOPLE IN COLOMBIA. https:
//www.ohchr.org/sites/default/files/Documents/Issues/SexualOrientation/
IESOGI/Academics/1912_Colombia_Report_English_FINAL.pdf
[24] Camille Cobb, Ted McCarthy, Annuska Perkins, Ankitha Bharadwaj, Jared
Comis, Brian Do, and Kate Starbird. 2014. Designing for the deluge: understand-
ing & supporting the distributed, collaborative work of crisis volunteers. In
Proceedings of the 17th ACM conference on Computer supported cooperative work
& social computing . 888–899.
[25] Patricia Hill Collins. 2019. Intersectionality as critical social theory . Duke
University Press.
[26] Patricia Hill Collins and Sirma Bilge. 2020. Intersectionality . John Wiley & Sons.
[27] Susan E Collins, Seema L Clifasefi, Joey Stanton, Kee JE Straits, Eleanor Gil-
Kashiwabara, Patricia Rodriguez Espinosa, Andel V Nicasio, Michele P Andrasik,
Starlyn M Hawes, Kimberly A Miller, et al .2018. Community-based participatory
research (CBPR): Towards equitable involvement of community in psychology
research. American Psychologist 73, 7 (2018), 884.
[28] Bill Cooke and Uma Kothari. 2001. Participation . Zed Books, London, England.
[29] Sasha Costanza-Chock. 2018. Design justice: Towards an intersectional feminist
framework for design theory and practice. Proceedings of the Design Research
Society (2018).
[30] Jakub Dalek, Nica Dumlao, Miles Kenyon, Irene Poetranto, Adam Senft, Caroline
Wesley, Arturo Filastò, Maria Xynou, and Amie Bishop. 2021. No Access: LGBTIQ
Website Censorship in Six Countries. (2021). https://citizenlab.ca/2021/08/no-
access-lgbtiq-website-censorship-in-six-countries/
[31] Deep Learning Indaba 2017. https://deeplearningindaba.com/2021/
[32] Sunipa Dev, Masoud Monajatipoor, Anaelia Ovalle, Arjun Subramonian, Jeff
Phillips, and Kai-Wei Chang. 2021. Harms of Gender Exclusivity and Chal-
lenges in Non-Binary Representation in Language Technologies. In Proceedings
of the 2021 Conference on Empirical Methods in Natural Language Processing .
Association for Computational Linguistics, Online and Punta Cana, Dominican
Republic, 1968–1994. https://doi.org/10.18653/v1/2021.emnlp-main.150
[33] Michael A DeVito, Ashley Marie Walker, and Jeremy Birnholtz. 2018. ’Too Gay
for Facebook’: Presenting LGBTQ+ Identity Throughout the Personal Social
Media Ecosystem. Proceedings of the ACM on Human-Computer Interaction 2,
CSCW (2018), 1–23.
[34] Michael A DeVito, Ashley Marie Walker, Caitlin Lustig, Amy J Ko, Katta Spiel,
Alex A Ahmed, Kimberley Allison, Morgan Scheuerman, Briana Dym, Jed R
Brubaker, et al .2020. Queer in HCI: Supporting LGBTQIA+ Researchers and
Research Across Domains. In Extended Abstracts of the 2020 CHI Conference on
Human Factors in Computing Systems . 1–4.
[35] Catherine D’ignazio and Lauren F Klein. 2020. Data feminism . MIT press.
[36] Diversity in AI (n.d.). http://www.diverseinai.org
[37] Jesse Dodge, Maarten Sap, Ana Marasović, William Agnew, Gabriel Ilharco, Dirk
Groeneveld, Margaret Mitchell, and Matt Gardner. 2021. Documenting Large
Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus. arXiv
preprint arXiv:2104.08758 (Nov. 2021), 1286–1305. https://doi.org/10.18653/v1/
2021.emnlp-main.98
[38] Jack Drescher. 2015. Out of DSM: Depathologizing homosexuality. Behavioral
sciences 5, 4 (2015), 565–575.
[39] Ashe Dryden. 2013. CODES OF CONDUCT 101 + FAQ. Link.
[40] Ashe Dryden. 2013. Increasing Diversity at Your Conference. Link.
[41] Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard S.
Zemel. 2012. Fairness through awareness. In Proceedings of the 3rd Innovations
in Theoretical Computer Science Conference . https://doi.org/10.1145/2090236.
2090255
[42] Russell Rowe Dynes. 1970. Organized behavior in disaster . Heath Lexington
Books.
[43] Val Elefante. 2021. Lips. Queer in AI Workshop at International Conference on
Machine Learning 2021 (2021). https://sites.google.com/view/queer-in-ai/icml-2021#h.lx7wo16mt2ax
[44] ELLIS. 2022. ELLIS PhD Program: Call for applications 2022. https://ellis.eu/
news/ellis-phd-program-call-for-applications-2022
[45] Myra Marx Ferree. 2016. The discursive politics of feminist intersectionality. In
Framing Intersectionality . Routledge, 55–65.
[46] Michelle Fine and María Elena Torre. 2006. Intimate details: Participatory action
research in prison. Action Research 4, 3 (2006), 253–269.
[47] Aoife Finn, Peter-Lucas Jones, Keoni Mahelona, Suzanne Duncan, and Gianna
Leoni. 2022. Developing a Part-Of-Speech tagger for te reo M ¯aori. In Proceedings
of the Fifth Workshop on the Use of Computational Methods in the Study of
Endangered Languages . 93–98.
[48] Luciano Floridi. 2019. Establishing the rules for building trustworthy AI. Nature
Machine Intelligence 1, 6 (2019), 261–262.
[49] Association for Computational Linguistics. (n.d.). https://www.aclweb.org/
[50] Jon Freeman. 2023. Letter to the NSF Director. https://static1.squarespace.
com/static/545d3fabe4b0811b5cc48193/t/63c867aefb89f3761070a5a3/
1674078140137/Letter+to+NSF+Director+-+LGBTQ%2B+Data_redacted.pdf
[51] Jonathan B. Freeman. 2020. Measuring and Resolving LGBTQ Disparities in
STEM. Policy Insights from the Behavioral and Brain Sciences 7 (2020), 141 – 148.
[52] Paolo Gaudiano. 2021. Exposure doesn’t pay: Why tech conferences should
compensate their speakers. https://www.forbes.com/sites/paologaudiano/2021/
06/07/how-to-make-conference-speaker-fees-more-inclusive-and-equitable/.
https://www.forbes.com/sites/paologaudiano/2021/06/07/how-to-make-
conference-speaker-fees-more-inclusive-and-equitable/
[53] Timnit Gebru and Emily Denton. 2021. Beyond Fairness. https://neurips.cc/
virtual/2021/tutorial/21889
[54] Christine Geeng, Mike Harris, Elissa Redmiles, and Franziska Roesner. 2021.
Queer Security Advice in the US. (2021).
[55] A Gomes, D Antonialli, and T Dias-Oliva. 2019. Drag queens and artificial
intelligence. Should computers decide what is toxic on the internet. Internet
Lab blog (2019). https://internetlab.org.br/en/news/drag-queens-and-artificial-
intelligence-should-computers-decide-what-is-toxic-on-the-internet/
[56] Mary L Gray and Siddharth Suri. 2019. Ghost work: How to stop Silicon Valley
from building a new global underclass . Eamon Dolan Books.
[57] LW Green, MA George, et al .2003. Appendix C: Guidelines for participatory
research in health promotion. In Community-based participatory research for
health , M. Minkler and N. Wallerstein (Eds.). San Francisco, CA, Jossey-Bass.
[58] Christina E. Gringeri, Stéphanie Wahab, and Ben Anderson-Nathe. 2010. What
Makes it Feminist?: Mapping the Landscape of Feminist Social Work Re-
search. Affilia 25, 4 (2010), 390–405. https://doi.org/10.1177/0886109910384072
arXiv:https://doi.org/10.1177/0886109910384072
[59] Kevin Guyan. 2022. Fixing the Wrong Problems: Queer Communities and the
False Promise of Unbiased and Equal Data Systems. European Data Protection
Law Review 8, 4 (2022). https://doi.org/10.21552/edpl/2022/4/5
[60] Karen Hacker and J. Glover Taylor. 2011. Community-Engaged Research
101. https://catalyst.harvard.edu/publications-documents/community-
engaged-research-101-2/
[61] Oliver Haug. 2021. TikTokers Are Using Grindr to Out LGBTQ+ Olympians,
Potentially Endangering Their Lives. Them (2021). https://www.them.us/story/
tiktokers-use-grindr-out-lgbtq-olympians/
[62] IEEE. (n.d.). IEEE Author Name Change Policy. https://conferences.
ieeeauthorcenter.ieee.org/author-ethics/guidelines-and-policies/ieee-author-
name-change-policy/ [Accessed Feb 2023].
[63] DisAbility in AI. (n.d.). https://elesa.github.io/ability_in_AI
[64] Indigenous in AI (n.d.). https://indigenousinai.org/
[65] Khari Johnson. 2021. Black and Queer AI Groups Say They’ll Spurn Google
Funding. Wired (2021). https://www.wired.com/story/black-queer-ai-groups-
spurn-google-funding/
[66] Khari Johnson. 2022. How Wrongful Arrests Based on AI Derailed 3 Men’s Lives.
Wired (2022). https://www.wired.com/story/wrongful-arrests-ai-derailed-3-
mens-lives/
[67] John Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov,
Olaf Ronneberger, Kathryn Tunyasuvunakool, Russ Bates, Augustin Žídek, Anna
Potapenko, Alex Bridgland, Clemens Meyer, Simon A A Kohl, Andrew J Bal-
lard, Andrew Cowie, Bernardino Romera-Paredes, Stanislav Nikolov, Rishub
Jain, Jonas Adler, Trevor Back, Stig Petersen, David Reiman, Ellen Clancy,
Michal Zielinski, Martin Steinegger, Michalina Pacholska, Tamas Bergham-
mer, Sebastian Bodenstein, David Silver, Oriol Vinyals, Andrew W Senior, Koray
Kavukcuoglu, Pushmeet Kohli, and Demis Hassabis. 2021. Highly accurate
protein structure prediction with AlphaFold. Nature 596, 7873 (2021), 583–589.
https://doi.org/10.1038/s41586-021-03819-2
[68] Pratyusha Kalluri. 2020. Don’t ask if artificial intelligence is good or fair, ask
how it shifts power. Nature 583, 169 (2020).
[69] Michael Katell, Meg Young, Dharma Dailey, Bernease Herman, Vivian Guetler,
Aaron Tam, Corinne Bintz, Daniella Raz, and PM Krafft. 2020. Toward situated
interventions for algorithmic equity: lessons from the field. In Proceedings of
the 2020 conference on fairness, accountability, and transparency . 45–55.
1893
Queer In AI: A Case Study in Community-Led Participatory AI FAccT ’23, June 12–15, 2023, Chicago, IL, USA
[70] Os Keyes. 2018. The misgendering machines: Trans/HCI implications of auto-
matic gender recognition. Proceedings of the ACM on human-computer interaction
2, CSCW (2018), 1–22. https://doi.org/10.1145/3274357
[71] Os Keyes. 2019. Counting the Countless: Why data science is a profound threat
for queer people. Real Life 2 (2019).
[72] Os Keyes, Zoë Hitzig, and Mwenza Blell. 2021. Truth from the machine: artificial
intelligence and the materialization of identity. Interdisciplinary Science Reviews
46 (2021), 158 – 175.
[73] Khipu. (n.d.). https://khipu.ai/committee-2023/
[74] Andrey Kormilitzin, Nenad Tomasev, Kevin R McKee, and Dan W Joyce. 2023. A
participatory initiative to include LGBT+ voices in AI for mental health. Nature
Medicine (2023), 1–2.
[75] Gary A Kreps and Susan Lovegren Bosworth. 1994. Organizing, role enactment,
and disaster: A structural theory . University of Delaware Press.
[76] Katie Langin. 2023. NSF still won’t track sexual orientation among scientific
workforce, prompting frustration. https://www.science.org/content/article/nsf-
still-won-t-track-sexual-orientation-among-scientific-workforce-prompting
[77] LatinX in AI (n.d.). https://www.latinxinai.org
[78] Neil Lawrence. 2021. Comment on pull request: Fix author name. https:
//github.com/mlresearch/v119/pull/4#issuecomment-760081621
[79] Jason Edward Lewis, Angie Abdilla, Noelani Arista, Kaipulaumakaniolono Baker,
Scott Benesiinaabandan, Michelle Brown, Melanie Cheung, Meredith Coleman,
Ashley Cordes, Joel Davison, et al .2020. Indigenous protocol and artificial
intelligence position paper. (2020).
[80] Yanan Long. 2021. Automatic Gender Recognition: Perspectives from Phe-
nomenological Hermeneutics. Queer in AI Workshop at International Confer-
ence on Machine Learning 2021 (2021). https://sites.google.com/view/queer-in-
ai/icml-2021#h.lx7wo16mt2ax
[81] Christina Lu, Jackie Kay, and Kevin McKee. 2022. Subverting machines, fluctu-
ating identities: Re-learning human categorization. In 2022 ACM Conference on
Fairness, Accountability, and Transparency . 1005–1015.
[82] Sarah Maiter, Laura Simich, Nora Jacobson, and Julie Wise. 2008. Reciprocity:
An ethic for community-based participatory action research. Action research 6,
3 (2008), 305–325.
[83] Miranda Marquit. 2018. Survey: 60% of LGBTQ Student Borrowers Regret
Taking Out Student Loans. (2018). https://www.lendingtree.com/student/lgbtq-
student-borrowers-regret-loans-survey/
[84] Masakhane (n.d.). https://www.masakhane.io
[85] Lyndsey McMillon-Brown. 2021. Implementing diversity, equity and inclusion
efforts at conferences. Nature Energy 6, 11 (2021), 1000–1002.
[86] Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram
Galstyan. 2021. A Survey on Bias and Fairness in Machine Learning. ACM
Comput. Surv. 54, 6, Article 115 (jul 2021), 35 pages. https://doi.org/10.1145/
3457607
[87] Doug Meyer. 2015. Violence against queer people: Race, class, gender, and the
persistence of anti-LGBT discrimination . Rutgers University Press.
[88] Muslims in ML. (n.d.). http://www.musiml.org/
[89] Name Change Policy Working Group (n.d.). Name Change Policy Working
Group. https://ncpwg.org/
[90] NeurIPS. (n.d.). NeurIPS Proceedings: Name Change Policy. https://papers.nips.
cc/, “Name Change Policy” link in footer [Accessed Feb 2023].
[91] North Africans in ML. (n.d.). https://sites.google.com/view/northafricansinml
[92] Molly Olmstead. 2021. A Prominent Priest Was Outed for Using Grindr. Experts
Say It’s a Warning Sign. Slate (2021). https://slate.com/technology/2021/07/
catholic-priest-grindr-data-privacy.html
[93] ORCID (n.d.). Open Researcher and Contributor ID (ORCID). https://orcid.org/
[94] Matt Payton. 2021. Egyptian police ’are using Grindr to find and arrest LGBT
people’. The Independent (2021). https://www.independent.co.uk/news/world/
africa/egyptian-police-grindr-dating-app-arrest-lgbt-gay-antigay-lesbian-
homophobia-a7211881.html
[95] Billy Perrigo. 2023. OpenAI Used Kenyan Workers on Less Than $2 Per Hour
to Make ChatGPT Less Toxic. Time (2023). https://time.com/6247678/openai-
chatgpt-kenya-workers/
[96] Anthony T Pinter, Morgan Klaus Scheuerman, and Jed R Brubaker. 2021. Enter-
ing Doors, Evading Traps: Benefits and Risks of Visibility During Transgender
Coming Outs. Proceedings of the ACM on Human-Computer Interaction 4, CSCW3
(2021), 1–27.
[97] Anastasia Powell, Adrian J Scott, and Nicola Henry. 2020. Digital harassment
and abuse: Experiences of sexuality and gender minority adults. European
journal of criminology 17, 2 (2020), 199–223.
[98] ACL Pubcheck. (n.d.). https://github.com/acl-org/aclpubcheck [Accessed Feb
2023].
[99] Queer in AI at NeurIPS 2021. http://queerinai.org/neurips-2021
[100] Queer in AI Organizers. 2019. Code of Conduct. https://sites.google.com/view/
queer-in-ai/code-of-conduct.
[101] Organizers of QueerInAI, A Pranav, MaryLena Bleile, Arjun Subramonian, Luca
Soldaini, Danica J. Sutherland, Sabine Weber, and Pan Xu. 2021. How to MakeVirtual Conferences Queer-Friendly: A Guide. In Proceedings of the 2021 Work-
shop on Widening NLP . Conference on Empirical Methods in Natural Language
Processing, Punta Cana, Dominican Republic. queerinai.org/diversity-guide
[102] Suman Ravuri, Karel Lenc, Matthew Willson, Dmitry Kangin, Remi Lam, Piotr
Mirowski, Megan Fitzsimons, Maria Athanassiadou, Sheleem Kashem, Sam
Madge, et al .2021. Skilful precipitation nowcasting using deep generative
models of radar. Nature 597, 7878 (2021), 672–677.
[103] Eva Reid. 2021. How To Make Conference Speaker Fees More Inclusive And
Equitable. hhttps://technical.ly/2021/07/22/conferences-pay-speakers//. https:
//technical.ly/2021/07/22/conferences-pay-speakers/
[104] Christina R. Richey, Katharine M N Lee, Erica M. Rodgers, and Kathryn B. H.
Clancy. 2019. Gender and sexual minorities in astronomy and planetary sci-
ence face increased risks of harassment and assault. Bulletin of the American
Astronomical Society 51 (2019), 0206.
[105] Nancy Russell, Susan Igras, Nalin Johri, Henrietta Kuoh, Melinda Pavin, and
Jane Wickstrom. 2008. ACQUIRE Project Working Paper. https://pdf.usaid.
gov/pdf_docs/Pnadm497.pdf
[106] Morgan Klaus Scheuerman, Aaron Jiang, Katta Spiel, and Jed R. Brubaker. 2021.
Revisiting Gendered Web Forms: An Evaluation of Gender Inputs with (Non-
)Binary People. In Proceedings of the 2021 CHI Conference on Human Factors in
Computing Systems (Yokohama, Japan) (CHI ’21) . Association for Computing
Machinery, New York, NY, USA, Article 400, 18 pages. https://doi.org/10.1145/
3411764.3445742
[107] Morgan Klaus Scheuerman, Madeleine Pape, and Alex Hanna. 2021. Auto-
essentialization: Gender in automated facial analysis as extended colonial project.
Big Data & Society 8, 2 (2021), 20539517211053712.
[108] Morgan Klaus Scheuerman, Jacob M Paul, and Jed R Brubaker. 2019. How
computers see gender: An evaluation of gender classification in commercial
facial analysis services. Proceedings of the ACM on Human-Computer Interaction
3, CSCW (2019), 1–33.
[109] Natalie Schluter. 2018. The glass ceiling in NLP. In Proceedings of the 2018
Conference on Empirical Methods in Natural Language Processing . 2793–2798.
[110] Sarah Schulman. 2021. Let the Record Show: A Political History of ACT UP New
York, 1987-1993 . Farrar, Straus and Giroux.
[111] Tom Simonite. 2021. AI and the List of Dirty, Naughty, Obscene, and Otherwise
Bad Words. Wired (2021). https://www.wired.com/story/ai-list-dirty-naughty-
obscene-bad-words/
[112] Mona Sloane, Emanuel Moss, Olaitan Awomolo, and Laura Forlano. 2022. Par-
ticipation Is Not a Design Fix for Machine Learning. In Equity and Access in
Algorithms, Mechanisms, and Optimization (Arlington, VA, USA) (EAAMO ’22) .
Association for Computing Machinery, New York, NY, USA, Article 1, 6 pages.
https://doi.org/10.1145/3551624.3555285
[113] Shakira Smith, Oliver L Haimson, Claire Fitzsimmons, and Nikki Echarte
Brown. 2021. Censorship of Marginalized Communities on Instagram. Salty
(2021). https://saltyworld.net/exclusive-report-censorship-of-marginalized-
communities-on-instagram-2021-pdf-download/
[114] Dean Spade. 2020. Mutual aid: Building solidarity during this crisis (and the next) .
Verso Books.
[115] Robyn Speer. 2021. Google Scholar deadnames trans authors and ob-
structs their name change. Link. https://docs.google.com/document/d/
1st05rXL1wcBBdgcMVqgN0X3L-6HGqORGfgnHMfXHKvE
[116] Robyn Speer. 2021. Google Scholar has failed us. (2021). https://scholar.hasfailed.
us/
[117] Kate Starbird and Leysia Palen. 2011. "Voluntweeters" self-organizing by digital
volunteers in times of crisis. In Proceedings of the SIGCHI conference on human
factors in computing systems . 1071–1080.
[118] Luke Stark and Jevan Hutson. 2021. Physiognomic Artificial Intelligence. Avail-
able at SSRN 3927300 32, 4 (2021), 922.
[119] Harini Suresh, Rajiv Movva, Amelia Lee Dogan, Rahul Bhargava, Isadora Cruxen,
Angeles Martinez Cuba, Guilia Taurino, Wonyoung So, and Catherine D’Ignazio.
2022. Towards Intersectional Feminist and Participatory ML: A Case Study
in Supporting Feminicide Counterdata Collection. In 2022 ACM Conference on
Fairness, Accountability, and Transparency (Seoul, Republic of Korea) (FAccT ’22) .
Association for Computing Machinery, New York, NY, USA, 667–678. https:
//doi.org/10.1145/3531146.3533132
[120] Danica J. Sutherland. 2022. Name Change Policies: A Brief (Personal) Tour.
Queer in AI workshop, NeurIPS 2022; https://djsutherland.ml/slides/qai-name-
change.
[121] Rajesh Tandon. 1988. Social transformation and participatory research. Conver-
gence 21, 2 (1988), 5.
[122] Theresa Jean Tanenbaum, Irving Rettig, H Michael Schwartz, BM Watson,
Teddy G Goetz, Katta Spiel, and Mike Hill. 2021. A vision for a more trans-
inclusive publishing world: guest article. Committee on Publication Ethics. https:
//publicationethics.org/news/vision-more-trans-inclusive-publishing-world.
[123] NAACL DEI Team. (n.d.). NAACL Citation Name Change Procedure. https:
//2021.naacl.org/blog/name-change-procedure/ [Accessed Feb 2023].
[124] Nenad Tomasev, Kevin R McKee, Jackie Kay, and Shakir Mohamed. 2021. Fairness
for Unobserved Characteristics: Insights from Technological Impacts on Queer
1894
FAccT ’23, June 12–15, 2023, Chicago, IL, USA Organizers of Queer in AI, et al.
Communities. arXiv preprint arXiv:2102.04257 (2021). https://doi.org/10.1145/
3461702.3462540
[125] Paige Yes Treebridge. 2021. Crowdsourcing a Corpus of Dogwhistle Transphobia.
Queer in AI Workshop at International Conference on Machine Learning 2021
(2021). https://sites.google.com/view/queer-in-ai/icml-2021#h.lx7wo16mt2ax
[126] Fangjing Tu. 2022. What can we learn from longitudinal studies
on the impacts of college internships? https://ccwt.wisc.edu/wp-
content/uploads/2022/04/Final_CCWT_report_LR-What-can-we-learn-
from-longitudinal-studies-on-the-impacts-of-college-internships.pdf
[127] Ayesha IT Tulloch. 2020. Improving sex and gender identity equity and inclusion
at conservation and ecology conferences. Nature Ecology & Evolution 4, 10 (2020),
1311–1320.
[128] Jessica Vamathevan, Dominic Clark, Paul Czodrowski, Ian Dunham, Edgardo
Ferran, George Lee, Bin Li, Anant Madabhushi, Parantu Shah, Michaela Spitzer,
et al.2019. Applications of machine learning in drug discovery and development.
Nature Reviews Drug discovery 18, 6 (2019), 463–477.[129] Lindsay Weinberg. 2022. Rethinking Fairness: An Interdisciplinary Survey of
Critiques of Hegemonic ML Fairness Approaches. Journal of Artificial Intelligence
Research 74 (2022), 75–109.
[130] Widening NLP (n.d.). http://www.winlp.org
[131] Bianca DM Wilson, Soon Kyu Choi, Gary W Harper, Marguerita Lightfoot,
Stephen Russell, and Ilan H Meyer. 2020. Homelessness among LGBT adults in
the US. https://williamsinstitute.law.ucla.edu/publications/lgbt-homelessness-
us/
[132] Women in Machine Learning. 2021. Code of Conduct. https://wimlworkshop.
org/conduct/.
[133] Women in Machine Learning (n.d.). https://wimlworkshop.org
[134] Aman Yadav, Christopher D Seals, Cristina M Soto Sullivan, Michael Lachney,
Quintana Clark, Kathy G Dixon, and Mark JT Smith. 2020. The forgotten scholar:
underrepresented minority postdoc experiences in STEM fields. Educational
Studies 56, 2 (2020), 160–185.
1895